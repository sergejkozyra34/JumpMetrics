import cv2
import mediapipe as mp
import numpy as np
import telebot
from telebot import types
import tempfile
import os
import logging
import time
import matplotlib.pyplot as plt

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

bot = telebot.TeleBot('YOUR_TELEGRAM_BOT_TOKEN')

mp_pose = mp.solutions.pose
pose = mp_pose.Pose(
    min_detection_confidence=0.7,
    min_tracking_confidence=0.7,
    model_complexity=1
)

USER_DATA = {}

main_markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
main_markup.row(types.KeyboardButton("üìè –ò–∑–º–µ—Ä–∏—Ç—å –ø—Ä—ã–∂–æ–∫"))
main_markup.row(types.KeyboardButton("üìè –£–∫–∞–∑–∞—Ç—å —Ä–æ—Å—Ç"), types.KeyboardButton("üîÑ –°–±—Ä–æ—Å–∏—Ç—å"))

def calculate_pixel_to_meter_ratio(calibration_frames, user_height):
    if not calibration_frames or user_height <= 0:
        return None
    
    heights_px = []
    for frame_data in calibration_frames:
        landmarks, frame_height = frame_data
        try:
            nose = landmarks[mp_pose.PoseLandmark.NOSE.value]
            left_ankle = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]
            right_ankle = landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value]
            
            ankle_mid_y = (left_ankle.y + right_ankle.y) * 0.5
            height_px = abs(nose.y - ankle_mid_y) * frame_height
            
            if height_px > 0:
                heights_px.append(height_px)
        except:
            pass
    
    if not heights_px:
        return None
    
    return np.mean(heights_px) / user_height

def analyze_jump(video_path, user_data):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return None, None

    pixel_per_meter = calculate_pixel_to_meter_ratio(user_data['calibration_frames'], user_data['height'])
    if pixel_per_meter is None:
        return None, None

    positions = []
    start_position = None
    calibration_complete = False
    jump_detected = False
    max_height = 0
    start_time = time.time()

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame = cv2.resize(frame, (640, 480))
        h, w = frame.shape[:2]
        
        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        
        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            
            left_ankle = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]
            right_ankle = landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value]
            ankle_mid = (
                (left_ankle.x + right_ankle.x) * 0.5 * w,
                (left_ankle.y + right_ankle.y) * 0.5 * h
            )
            
            if not calibration_complete:
                if time.time() - start_time > 3:
                    calibration_complete = True
                    start_position = ankle_mid
                continue
            
            positions.append(ankle_mid)
            
            current_height = ankle_mid[1]
            if not jump_detected and current_height < start_position[1] - 0.05 * h:
                jump_detected = True
            
            if jump_detected:
                max_height = max(max_height, start_position[1] - current_height)

    cap.release()
    
    if not positions:
        return None, None
    
    jump_height = min(max_height / pixel_per_meter, 2.0)
    
    start_x = start_position[0]
    end_x = positions[-1][0]
    jump_length = min(abs(end_x - start_x) / pixel_per_meter * 0.7, 4.0)
    
    return jump_height, jump_length

def create_results_plot(height, length):
    fig, ax = plt.subplots(figsize=(10, 5))
    bars = ax.bar(['–í—ã—Å–æ—Ç–∞ –ø—Ä—ã–∂–∫–∞', '–î–ª–∏–Ω–∞ –ø—Ä—ã–∂–∫–∞'], [height, length], color=['#4CAF50', '#2196F3'])
    ax.set_ylabel('–ú–µ—Ç—Ä—ã')
    ax.set_title('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –ø—Ä—ã–∂–∫–∞')
    ax.grid(axis='y', linestyle='--', alpha=0.7)
    
    for bar in bars:
        h = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., h, f'{h:.2f} –º', ha='center', va='bottom')
    
    plot_path = 'jump_results.png'
    plt.savefig(plot_path, bbox_inches='tight', dpi=100)
    plt.close()
    return plot_path

@bot.message_handler(commands=['start', 'help'])
def send_welcome(message):
    user_id = message.from_user.id
    if user_id not in USER_DATA:
        USER_DATA[user_id] = {'height': None, 'state': 'waiting', 'calibration_frames': []}
    
    bot.send_message(
        message.chat.id,
        "üèÜ *–¢–æ—á–Ω—ã–π –∏–∑–º–µ—Ä–∏—Ç–µ–ª—å –ø—Ä—ã–∂–∫–æ–≤*\n\n–û—Ç–ø—Ä–∞–≤—å –≤–∏–¥–µ–æ –ø—Ä—ã–∂–∫–∞ –ø–æ—Å–ª–µ —É–∫–∞–∑–∞–Ω–∏—è —Ä–æ—Å—Ç–∞.",
        reply_markup=main_markup,
        parse_mode='Markdown'
    )

@bot.message_handler(func=lambda message: message.text == "üìè –£–∫–∞–∑–∞—Ç—å —Ä–æ—Å—Ç")
def request_height(message):
    msg = bot.send_message(message.chat.id, "–í–≤–µ–¥–∏ —Å–≤–æ–π —Ä–æ—Å—Ç –≤ –º–µ—Ç—Ä–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1.75):", reply_markup=types.ForceReply())
    bot.register_next_step_handler(msg, process_height_step)

def process_height_step(message):
    user_id = message.from_user.id
    try:
        height = float(message.text.replace(',', '.'))
        if 1.0 <= height <= 2.5:
            USER_DATA[user_id]['height'] = height
            bot.send_message(message.chat.id, f"‚úÖ –†–æ—Å—Ç {height:.2f} –º —Å–æ—Ö—Ä–∞–Ω–µ–Ω!", reply_markup=main_markup)
        else:
            raise ValueError()
    except:
        bot.send_message(message.chat.id, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –í–≤–µ–¥–∏ —á–∏—Å–ª–æ –æ—Ç 1.0 –¥–æ 2.5", reply_markup=main_markup)

@bot.message_handler(func=lambda message: message.text == "üîÑ –°–±—Ä–æ—Å–∏—Ç—å")
def reset_user(message):
    user_id = message.from_user.id
    USER_DATA[user_id] = {'height': None, 'state': 'waiting', 'calibration_frames': []}
    bot.send_message(message.chat.id, "üîÑ –î–∞–Ω–Ω—ã–µ —Å–±—Ä–æ—à–µ–Ω—ã", reply_markup=main_markup)

@bot.message_handler(func=lambda message: message.text == "üìè –ò–∑–º–µ—Ä–∏—Ç—å –ø—Ä—ã–∂–æ–∫")
def request_video(message):
    user_id = message.from_user.id
    if user_id not in USER_DATA or USER_DATA[user_id]['height'] is None:
        bot.send_message(message.chat.id, "–°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏ —Ä–æ—Å—Ç", reply_markup=main_markup)
        return
    
    USER_DATA[user_id]['state'] = 'waiting_video'
    USER_DATA[user_id]['calibration_frames'] = []
    bot.send_message(message.chat.id, "–û—Ç–ø—Ä–∞–≤—å –≤–∏–¥–µ–æ –ø—Ä—ã–∂–∫–∞ (–ø–µ—Ä–≤—ã–µ 3 —Å–µ–∫ —Å—Ç–æ–π –Ω–µ–ø–æ–¥–≤–∏–∂–Ω–æ)", reply_markup=main_markup)

@bot.message_handler(content_types=['video', 'video_note'])
def handle_video(message):
    user_id = message.from_user.id
    if user_id not in USER_DATA or USER_DATA[user_id]['state'] != 'waiting_video':
        return

    try:
        file_id = message.video_note.file_id if message.content_type == 'video_note' else message.video.file_id
        file_info = bot.get_file(file_id)
        downloaded_file = bot.download_file(file_info.file_path)
        
        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_video:
            temp_video.write(downloaded_file)
            temp_video_path = temp_video.name
        
        bot.send_message(message.chat.id, "üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...", reply_markup=main_markup)
        
        cap = cv2.VideoCapture(temp_video_path)
        calibration_frames = []
        start_time = time.time()
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame = cv2.resize(frame, (640, 640) if message.content_type == 'video_note' else (640, 480))
            results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            
            if results.pose_landmarks and time.time() - start_time < 3.0:
                calibration_frames.append((results.pose_landmarks.landmark, frame.shape[0]))
        
        cap.release()
        
        if len(calibration_frames) < 10:
            raise ValueError("–ù—É–∂–Ω–æ —Å—Ç–æ—è—Ç—å –Ω–µ–ø–æ–¥–≤–∏–∂–Ω–æ –ø–µ—Ä–≤—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã")
        
        USER_DATA[user_id]['calibration_frames'] = calibration_frames
        height, length = analyze_jump(temp_video_path, USER_DATA[user_id])
        os.unlink(temp_video_path)
        
        if height is not None and length is not None:
            plot = create_results_plot(height, length)
            with open(plot, 'rb') as p:
                bot.send_photo(
                    message.chat.id, 
                    p, 
                    caption=f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n–í—ã—Å–æ—Ç–∞: {height:.2f} –º\n–î–ª–∏–Ω–∞: {length:.2f} –º",
                    reply_markup=main_markup
                )
            os.unlink(plot)
        else:
            bot.send_message(message.chat.id, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–º–µ—Ä–∏—Ç—å –ø—Ä—ã–∂–æ–∫", reply_markup=main_markup)
    
    except Exception as e:
        bot.reply_to(message, f"‚ùå –û—à–∏–±–∫–∞: {str(e)}", reply_markup=main_markup)
        if 'temp_video_path' in locals() and os.path.exists(temp_video_path):
            os.unlink(temp_video_path)

if __name__ == "__main__":
    bot.infinity_polling()